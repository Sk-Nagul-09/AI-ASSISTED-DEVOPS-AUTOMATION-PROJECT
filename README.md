# ğŸ¤–ğŸ³ AI-Assisted DevOps Automation
## âš¡ GenAI Powered Dockerfile Generator

ğŸš€ Automate Dockerfile creation using Generative AI.

This project generates **production-ready Dockerfiles** based on the programming language provided by the user.

Instead of writing Dockerfiles manually, this tool creates optimized and standardized configurations in seconds.

---

## ğŸ“Œ Project Overview

In real DevOps workflows, writing Dockerfiles is repetitive and error-prone.

This tool uses a locally running Large Language Model via **Ollama** and the **Llama 3** model to automatically generate Dockerfiles following best practices.

âœ… Faster containerization  
âœ… Standardized configurations  
âœ… Reduced manual effort  
âœ… Improved productivity  

---

## ğŸ¯ Features

âœ¨ Generate Dockerfiles instantly  
âœ¨ Supports multiple programming languages  
âœ¨ Uses container best practices  
âœ¨ Runs locally (no cloud API required)  
âœ¨ Keeps source code private & secure  

---

## ğŸ›  Tech Stack

| ğŸ”§ Technology | ğŸš€ Purpose |
|--------------|-----------|
| ğŸ Python | Application logic |
| ğŸ¤– Generative AI | Dockerfile generation |
| ğŸ§  Ollama | Local LLM runtime |
| ğŸ³ Docker | Containerization |
| âš™ Prompt Engineering | Controlled output |

---

## âš™ï¸ Prerequisites

### 1ï¸âƒ£ Install Ollama

#### Linux
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Start Ollama:
```bash
ollama serve
```

### Pull model:
```bash
ollama pull llama3.2:1b
```

### 2ï¸âƒ£ Start Ollama Service
```
ollama serve
```

### 3ï¸âƒ£ Pull Llama Model
```
ollama pull llama3.1:8b
```

### ğŸš€ Project Setup

1ï¸âƒ£ Clone Repository
```
git clone https://github.com/Sk-Nagul-09/AI-ASSISTED-DEVOPS-AUTOMATION-PROJECT.git
cd ai-dockerfile-generator
```

### 2ï¸âƒ£ Create Virtual Environment
```
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```
pip install -r requirements.txt
```

### â–¶ï¸ Run the Application
```
python3 generate_dockerfile.py
```

### ğŸ’¬ Example Input
```
Enter the programming language: python
```

| Step | Description                                 |
| ---- | ------------------------------------------- |
| 1ï¸âƒ£  | User enters programming language            |
| 2ï¸âƒ£  | Script sends structured prompt to local LLM |
| 3ï¸âƒ£  | LLM generates optimized Dockerfile          |
| 4ï¸âƒ£  | Dockerfile is displayed instantly           |


### ğŸ³ Example Output
```
FROM amazonlinux:latest
RUN yum update -y
RUN yum install -y python3 python3-pip
RUN pip3 install flask
WORKDIR /opt/python_webapp
COPY app.py .
CMD FLASK_APP=app.py flask run --host=0.0.0.0 --port=8082
EXPOSE 8082
```

ğŸ” Why Run AI Locally?
---

âœ” Keeps source code private

âœ” Eliminates API costs

âœ” Works without external AI services

âœ” Suitable for enterprise security policies


### ğŸ”® Future Enhancements
---

ğŸš€ Generate Kubernetes manifests

ğŸš€ Create CI/CD pipeline templates

ğŸš€ Auto-generate shell scripts

ğŸš€ Framework detection & dependency handling

ğŸš€ Multi-stage & optimized production builds


### ğŸ¯ Learning Outcomes
---

âœ… DevOps automation using AI

âœ… Prompt engineering fundamentals

âœ… Docker containerization best practices

âœ… Local LLM integration

âœ… Secure AI usage in DevOps workflows

